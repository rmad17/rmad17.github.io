+++
title = 'Database Design'
date = 2025-09-01T01:00:28+05:30
draft = true
+++

# Database Design: A Product-First Approach to Building Scalable Systems

After years of building database architectures for high-scale applications, I've developed a clear understanding of what separates successful systems from those that crumble under real-world product demands. Database design is often approached through the lens of technical optimizationâ€”normalized tables, efficient indexes, and query performance. While these technical aspects remain crucial, my experience across diverse projects has shown that the most successful architectures emerge from a deep understanding of the product they serve.

This article shares insights from three distinct projects, each with unique challenges that shaped my approach to product-centric database design.

## ğŸ¯ Product-Centric Database Design Framework

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ¯ Product    â”‚â”€â”€â”€â–¶â”‚   ğŸ—ï¸ Schema     â”‚â”€â”€â”€â–¶â”‚   ğŸš€ Product       â”‚
â”‚    Analysis     â”‚    â”‚     Design      â”‚    â”‚    Success         â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                    â”‚
â”‚ â€¢ User Workflowsâ”‚    â”‚ â€¢ API Patterns  â”‚    â”‚ â€¢ User Satisfactionâ”‚
â”‚ â€¢ Business      â”‚    â”‚ â€¢ Scale Planningâ”‚    â”‚ â€¢ Business Goals   â”‚
â”‚   Context       â”‚    â”‚                 â”‚    â”‚                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Core Principles:**
âœ… Understand user workflows before schema design  
âœ… Design for product roadmap evolution  
âœ… Optimize for actual usage patterns  
âœ… Measure product outcomes over technical metrics

---

## Three Case Studies: Different Products, Different Solutions

| **Use Case** | **Core Challenge** | **Key Strategy** | **Primary Focus** |
|--------------|-------------------|------------------|-------------------|
| ğŸ† **Fantasy Gaming** | High reads + burst scaling | Denormalization + caching | Read optimization |
| âœˆï¸ **Airline Reservations** | Schema evolution | Version management | Flexibility |
| ğŸ’° **Loan Management** | Operational scaling | Strategic denormalization | Process efficiency |

---

# Case Study 1: Fantasy Football App - Optimizing for Read-Heavy Workloads

## The Challenge: 100x Traffic Spikes During Live Matches

The fantasy football platform presented a classic read-heavy scenario with extreme burst scaling requirements. During match days, concurrent users jumped from 500 to 50,000+ (100x spike) as users obsessively checked live scores and player statistics.

## ğŸ“Š Traffic Pattern Analysis

```
Concurrent Users (thousands)
â”‚
50â”œ    â–ˆâ–ˆ                      â–ˆâ–ˆ
  â”‚    â–ˆâ–ˆ                      â–ˆâ–ˆ
40â”œ    â–ˆâ–ˆ                      â–ˆâ–ˆ
  â”‚    â–ˆâ–ˆ                      â–ˆâ–ˆ
30â”œ    â–ˆâ–ˆ                      â–ˆâ–ˆ
  â”‚    â–ˆâ–ˆ                      â–ˆâ–ˆ
20â”œ    â–ˆâ–ˆ                      â–ˆâ–ˆ
  â”‚    â–ˆâ–ˆ                      â–ˆâ–ˆ
10â”œ    â–ˆâ–ˆ                      â–ˆâ–ˆ
  â”‚ â–„â–„â–„â–ˆâ–ˆâ–„â–„â–„ â–„â–„â–„ â–„â–„â–„ â–„â–„â–„ â–„â–„â–„â–ˆâ–ˆâ–„â–„â–„
 0â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Mon Tue Wed Thu Fri Sat   Sun
```

**Key Insights:**
- **Read vs Write Ratio:** 15:1 (users check 15x more than they change)
- **Peak Duration:** 6 hours across multiple match kickoffs
- **Critical Path:** Live player statistics during matches

## Database Architecture: Strategic Denormalization

Instead of a normalized approach, I designed for query efficiency with strategic denormalization:

### Primary Tables (Normalized Source of Truth)

**Players Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| player_id | SERIAL | Primary key | 1001 |
| name | VARCHAR(100) | Player name | "Mohamed Salah" |
| team_id | INTEGER | Reference to team | 15 |
| position | VARCHAR(20) | Playing position | "Forward" |

**Matches Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| match_id | SERIAL | Primary key | 2024001 |
| home_team_id | INTEGER | Home team reference | 15 |
| away_team_id | INTEGER | Away team reference | 8 |
| match_date | TIMESTAMP | Match date/time | "2024-03-15 15:00:00" |
| gameweek | INTEGER | Season gameweek | 28 |

**Match Stats Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| stat_id | SERIAL | Primary key | 50001 |
| player_id | INTEGER | Reference to player | 1001 |
| match_id | INTEGER | Reference to match | 2024001 |
| goals | INTEGER | Goals scored | 2 |
| assists | INTEGER | Assists made | 1 |
| minutes_played | INTEGER | Minutes on field | 90 |
| tackles | INTEGER | Tackles made | 3 |
| passes_completed | INTEGER | Successful passes | 45 |
| shots_on_target | INTEGER | Shots on target | 4 |

### Denormalized Performance Tables

The key insight was that users frequently requested the same data patterns:
- Home vs Away performance comparison
- Recent form (last 5 matches)
- Season aggregates by position

**Player Performance Summary Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| player_id | INTEGER | Reference to player | 1001 |
| season | INTEGER | Season year | 2024 |
| total_matches | INTEGER | Total matches played | 25 |
| total_goals | INTEGER | Total goals scored | 18 |
| total_assists | INTEGER | Total assists made | 12 |
| total_points | INTEGER | Fantasy points earned | 245 |
| home_matches | INTEGER | Home matches played | 13 |
| home_goals | INTEGER | Goals at home | 12 |
| home_assists | INTEGER | Assists at home | 7 |
| home_points | INTEGER | Home fantasy points | 135 |
| away_matches | INTEGER | Away matches played | 12 |
| away_goals | INTEGER | Goals away | 6 |
| away_assists | INTEGER | Assists away | 5 |
| away_points | INTEGER | Away fantasy points | 110 |
| recent_form_points | INTEGER[] | Last 5 match points | [15, 8, 12, 6, 11] |
| recent_form_summary | TEXT | Form description | "Excellent form - 3 goals in last 2" |
| position | VARCHAR(20) | Playing position | "Forward" |
| clean_sheets | INTEGER | Clean sheets (defenders) | 0 |
| saves | INTEGER | Saves (goalkeepers) | 0 |
| key_passes | INTEGER | Key passes (midfielders) | 0 |
| last_updated | TIMESTAMP | Last update time | "2024-03-15 18:30:00" |

### Team Standings Optimization

Since users frequently compared team standings for home/away analysis:

**Team Standings Extended Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| team_id | INTEGER | Team reference | 15 |
| season | INTEGER | Season year | 2024 |
| position | INTEGER | Overall league position | 2 |
| matches_played | INTEGER | Total matches played | 28 |
| wins | INTEGER | Total wins | 20 |
| draws | INTEGER | Total draws | 5 |
| losses | INTEGER | Total losses | 3 |
| goals_for | INTEGER | Goals scored | 68 |
| goals_against | INTEGER | Goals conceded | 22 |
| points | INTEGER | League points | 65 |
| home_position | INTEGER | Home form position | 1 |
| home_wins | INTEGER | Home wins | 12 |
| home_draws | INTEGER | Home draws | 2 |
| home_losses | INTEGER | Home losses | 0 |
| home_goals_for | INTEGER | Home goals scored | 42 |
| home_goals_against | INTEGER | Home goals conceded | 8 |
| away_position | INTEGER | Away form position | 4 |
| away_wins | INTEGER | Away wins | 8 |
| away_draws | INTEGER | Away draws | 3 |
| away_losses | INTEGER | Away losses | 3 |
| away_goals_for | INTEGER | Away goals scored | 26 |
| away_goals_against | INTEGER | Away goals conceded | 14 |
| last_updated | TIMESTAMP | Last update time | "2024-03-15 17:00:00" |

## Read Optimization Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Primary DB     â”‚â”€â”€â–¶â”‚  Read Replica 1 â”‚â”€â”€â–¶â”‚  Read Replica 2 â”‚â”€â”€â–¶â”‚   Redis Cache   â”‚
â”‚                 â”‚   â”‚                 â”‚   â”‚                 â”‚   â”‚                 â”‚
â”‚ â€¢ Live Updates  â”‚   â”‚ â€¢ User Teams    â”‚   â”‚ â€¢ Leaderboards  â”‚   â”‚ â€¢ Player Stats  â”‚
â”‚ â€¢ Match Stats   â”‚   â”‚ â€¢ Player Data   â”‚   â”‚ â€¢ Standings     â”‚   â”‚ â€¢ Common Queriesâ”‚
â”‚ â€¢ Write Heavy   â”‚   â”‚ â€¢ Profile Info  â”‚   â”‚ â€¢ League Tables â”‚   â”‚ â€¢ 30min TTL     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## API Query Optimization Examples

**Before (Normalized - 7 table joins):**
Common API call: "Get Mohamed Salah's season summary with recent form"
- Required tables: Players â†’ Teams â†’ Match_Stats â†’ Game_Results â†’ Team_Schedules â†’ Opponent_Stats â†’ Weather_Conditions  
- Response time: 3-8 seconds (unusable on mobile)
- Database load: High CPU usage during peak traffic

**After (Denormalized - Single table lookup):**
Same API call using Player_Performance_Summary table:
- Required tables: Single table lookup from player_performance_summary
- Response time: <200ms (excellent mobile experience)
- Database load: Minimal CPU usage
- Storage trade-off: +2GB for 15x faster mobile experience

**Query Pattern Comparison:**

| Query Type | Normalized Approach | Denormalized Approach | Performance Gain |
|------------|-------------------|---------------------|------------------|
| Player season stats | 7 table joins | Single table SELECT | 15-40x faster |
| Team standings | 5 table joins | Direct lookup | 10-25x faster |
| Home/Away comparison | 8 table joins + calculations | Pre-calculated columns | 20-50x faster |
| Recent form analysis | Complex window functions | Array column lookup | 30x faster |

## Results Achieved

| Metric | Before | After | Improvement |
|--------|--------|--------|-------------|
| **Peak Load Handling** | System failure | 50k concurrent users | âˆ |
| **API Response Time** | 3-8 seconds | <200ms | 15-40x faster |
| **Database Load** | 100% during peaks | 10% during peaks | 90% reduction |
| **Storage Trade-off** | - | +2GB for summaries | Acceptable |

---

# Case Study 2: Airline Reservation System - Schema Evolution Management

## The Challenge: NDC Version Compatibility

The airline industry's challenge centered on IATA's New Distribution Capability (NDC) schema evolution. Airlines implement different NDC versions (17.2, 19.1, 21.3, 24.1) with no standardization, requiring support for multiple versions simultaneously while converting between client-specific versions.

## NDC Version Management Architecture

### Core Challenge Visualization

```
Client Request (NDC 19.1) â”€â”€â”
                            â”‚
Client Request (NDC 17.2) â”€â”€â”¼â”€â”€â–¶ Our System (NDC 17-18 Base) â”€â”€â”
                            â”‚                                   â”‚
Client Request (NDC 21.3) â”€â”€â”˜                                   â”‚
                                                                 â–¼
                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                           â”‚  Version Conversion Engine  â”‚
                                           â”‚                             â”‚
                                           â”‚ Input: Any NDC Version      â”‚
                                           â”‚ Storage: Our Base Version   â”‚
                                           â”‚ Output: Client's Version    â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Database Schema Design for Version Flexibility

**NDC Messages Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| message_id | UUID | Primary key | "a1b2c3d4-e5f6-7890-abcd-ef1234567890" |
| message_type | VARCHAR(50) | NDC message type | "AirShopping" |
| input_version | VARCHAR(10) | Original client version | "19.1" |
| storage_version | VARCHAR(10) | Our normalized version | "17.2" |
| client_version | VARCHAR(10) | Expected response version | "19.1" |
| original_xml | TEXT | Original client message | "&lt;AirShoppingRQ Version='19.1'&gt;..." |
| normalized_xml | TEXT | Converted to base version | "&lt;AirShoppingRQ Version='17.2'&gt;..." |
| airline_code | VARCHAR(3) | IATA airline code | "BA" |
| created_at | TIMESTAMP | Creation timestamp | "2024-03-15 10:30:00" |
| processed_at | TIMESTAMP | Processing timestamp | "2024-03-15 10:30:02" |

**NDC Version Extensions Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| extension_id | UUID | Primary key | "ext-uuid-123" |
| message_id | UUID | Reference to NDC message | "a1b2c3d4-e5f6-7890-abcd-ef1234567890" |
| from_version | VARCHAR(10) | First version with feature | "19.1" |
| to_version | VARCHAR(10) | Last version (NULL=active) | NULL |
| extension_type | VARCHAR(50) | Type of extension | "PaymentMethods" |
| extension_path | VARCHAR(200) | XPath to element | "//PaymentMethods/Method" |
| extension_data | JSONB | Flexible data storage | {"creditCard": {"types": ["VISA","MC"]}} |
| is_backward_compatible | BOOLEAN | Backward compatibility | false |
| conversion_rule | TEXT | Conversion instructions | "Map to legacy payment format" |

**NDC Version Compatibility Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| from_version | VARCHAR(10) | Source version | "19.1" |
| to_version | VARCHAR(10) | Target version | "17.2" |
| compatibility_level | VARCHAR(20) | Compatibility type | "CONVERSION_NEEDED" |
| conversion_rules | JSONB | Conversion instructions | {"removeElements": ["PaymentMethods"]} |
| data_loss_warnings | TEXT[] | Potential data loss | ["Advanced payment methods not supported"] |

### Version Conversion Strategy

The system handles three conversion scenarios:

**1. Inbound Conversion (Client â†’ Our System)**
```sql
-- Convert incoming NDC message to our base version
CREATE OR REPLACE FUNCTION convert_ndc_inbound(
    input_xml TEXT,
    input_version VARCHAR(10),
    target_version VARCHAR(10) DEFAULT '17.2'
) RETURNS TABLE (
    normalized_xml TEXT,
    conversion_warnings TEXT[],
    extensions_extracted JSONB
) AS $$
BEGIN
    -- Apply version-specific transformations
    -- Extract extensions not supported in base version
    -- Return normalized message + extracted extensions
END;
$$ LANGUAGE plpgsql;
```

**2. Storage Optimization**

**Flight Offers Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| offer_id | UUID | Primary key | "offer-uuid-456" |
| departure_airport | VARCHAR(3) | IATA departure code | "LHR" |
| arrival_airport | VARCHAR(3) | IATA arrival code | "JFK" |
| departure_time | TIMESTAMP | Departure date/time | "2024-04-15 10:30:00" |
| arrival_time | TIMESTAMP | Arrival date/time | "2024-04-15 18:45:00" |
| airline_code | VARCHAR(3) | Operating airline | "BA" |
| flight_number | VARCHAR(10) | Flight number | "BA179" |
| aircraft_type | VARCHAR(10) | Aircraft model | "777-300ER" |
| base_price | DECIMAL(10,2) | Base fare price | 599.99 |
| currency | VARCHAR(3) | Price currency | "USD" |
| additional_data | JSONB | Version-specific data | {"cabinClass": "Economy", "fareBasis": "Y"} |
| source_version | VARCHAR(10) | Original NDC version | "19.1" |
| created_at | TIMESTAMP | Creation timestamp | "2024-03-15 10:30:00" |

**Offer Version Features Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| feature_id | UUID | Primary key | "feature-uuid-789" |
| offer_id | UUID | Reference to offer | "offer-uuid-456" |
| feature_type | VARCHAR(50) | Type of feature | "Baggage" |
| version_introduced | VARCHAR(10) | First supporting version | "19.1" |
| feature_data | JSONB | Feature details | {"weight": "23kg", "included": true} |
| fallback_behavior | VARCHAR(100) | Backward compatibility | "Include in base price" |

**3. Outbound Conversion (Our System â†’ Client)**
```sql
-- Convert our normalized data to client's expected version
CREATE OR REPLACE FUNCTION convert_ndc_outbound(
    offer_data JSONB,
    target_version VARCHAR(10),
    client_capabilities JSONB DEFAULT '{}'
) RETURNS TEXT AS $$
BEGIN
    -- Build XML in target version format
    -- Include/exclude features based on version support
    -- Apply client-specific customizations
    RETURN constructed_xml;
END;
$$ LANGUAGE plpgsql;
```

## Version Migration Strategy

When new NDC versions are released:

```sql
-- Migration process for new NDC version support
CREATE OR REPLACE FUNCTION add_ndc_version_support(
    new_version VARCHAR(10),
    migration_rules JSONB
) RETURNS BOOLEAN AS $$
BEGIN
    -- 1. Add version to compatibility matrix
    INSERT INTO ndc_version_compatibility 
    (from_version, to_version, compatibility_level, conversion_rules)
    SELECT base_version, new_version, 'CONVERSION_NEEDED', migration_rules
    FROM (SELECT '17.2' as base_version) base;
    
    -- 2. Update extension mapping for new features
    -- 3. Test conversion functions
    -- 4. Enable gradual rollout
    
    RETURN true;
END;
$$ LANGUAGE plpgsql;
```

## Results Achieved

| Metric | Result | Description |
|--------|---------|-------------|
| **Version Support** | `6 versions` | Concurrent NDC version support |
| **Migration Time** | `2-3 days` | Time to add new version support |
| **Zero Downtime** | `âœ“` | No service interruption for updates |
| **Client Compatibility** | `100%` | All client versions supported |

---

# Case Study 3: Loan Management System - Scaling for Operational Complexity

## The Challenge: Evolving Regulatory Requirements

The loan management system needed to scale not just for volume, but for operational complexity. As the business evolvedâ€”from basic lending to obtaining NBFC license from RBIâ€”the number of process steps, compliance requirements, and data relationships grew exponentially.

## Operational Evolution Timeline

```
Basic Lending â†’ P2P License â†’ NBFC License â†’ Banking Partnership
     â”‚              â”‚             â”‚               â”‚
   5 steps       12 steps      25 steps       40+ steps
     â”‚              â”‚             â”‚               â”‚
Basic KYC      Enhanced KYC   Full KYC      Enhanced Due
Documents      + Credit       + Income      Diligence +
               Bureau         Verification   Risk Assessment
```

### Loan Lifecycle Database Design

The loan management system follows a clear lifecycle from application to closure. Here's the optimized database structure:

**User Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| user_id | UUID | Primary key | "user-uuid-001" |
| full_name | VARCHAR(100) | Full legal name | "Rajesh Kumar Singh" |
| email | VARCHAR(100) | Email address | "rajesh.singh@email.com" |
| phone | VARCHAR(15) | Mobile number | "+919876543210" |
| pan_number | VARCHAR(10) | PAN card number | "ABCDE1234F" |
| aadhar_number | VARCHAR(12) | Aadhar card number | "123456789012" |
| credit_score | INTEGER | Latest credit score | 750 |
| annual_income | DECIMAL(12,2) | Annual income | 1200000.00 |
| employment_type | VARCHAR(50) | Type of employment | "Salaried" |
| employer_name | VARCHAR(100) | Current employer | "Tech Solutions Pvt Ltd" |
| kyc_status | VARCHAR(20) | KYC verification status | "VERIFIED" |
| risk_category | VARCHAR(20) | Risk assessment | "LOW" |
| created_at | TIMESTAMP | Account creation | "2024-01-15 10:30:00" |
| last_updated | TIMESTAMP | Last profile update | "2024-03-15 14:20:00" |

**Loan Request Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| request_id | UUID | Primary key | "req-uuid-001" |
| user_id | UUID | Reference to user | "user-uuid-001" |
| loan_amount | DECIMAL(12,2) | Requested amount | 500000.00 |
| loan_purpose | VARCHAR(100) | Purpose of loan | "Home Purchase" |
| loan_type | VARCHAR(50) | Type of loan | "Home Loan" |
| tenure_months | INTEGER | Requested tenure | 240 |
| requested_roi | DECIMAL(5,2) | Requested interest rate | 8.5 |
| monthly_income | DECIMAL(12,2) | Declared monthly income | 100000.00 |
| existing_emis | DECIMAL(10,2) | Current EMI obligations | 15000.00 |
| collateral_value | DECIMAL(12,2) | Collateral property value | 800000.00 |
| request_status | VARCHAR(30) | Current status | "UNDER_PROCESSING" |
| submitted_at | TIMESTAMP | Submission timestamp | "2024-02-01 09:15:00" |
| last_updated | TIMESTAMP | Last status update | "2024-02-15 16:45:00" |

**Loan Approval Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| approval_id | UUID | Primary key | "appr-uuid-001" |
| request_id | UUID | Reference to loan request | "req-uuid-001" |
| approved_amount | DECIMAL(12,2) | Sanctioned amount | 450000.00 |
| approved_roi | DECIMAL(5,2) | Approved interest rate | 9.25 |
| approved_tenure | INTEGER | Approved tenure months | 240 |
| processing_fee | DECIMAL(10,2) | Processing fee | 5000.00 |
| approval_conditions | TEXT | Special conditions | "Property insurance mandatory" |
| approval_status | VARCHAR(30) | Final approval status | "APPROVED" |
| approved_by | VARCHAR(100) | Approving authority | "Senior Credit Manager" |
| approval_date | TIMESTAMP | Approval timestamp | "2024-02-20 11:30:00" |
| expiry_date | TIMESTAMP | Offer expiry | "2024-03-20 23:59:59" |
| rejection_reason | TEXT | Reason if rejected | NULL |
| credit_committee_notes | TEXT | Internal committee notes | "Good credit profile, stable income" |

**Loan Disbursal Table**  
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| disbursal_id | UUID | Primary key | "disb-uuid-001" |
| approval_id | UUID | Reference to approval | "appr-uuid-001" |
| loan_account_number | VARCHAR(20) | Unique loan account | "HL202400001" |
| disbursed_amount | DECIMAL(12,2) | Amount disbursed | 450000.00 |
| principal_amount | DECIMAL(12,2) | Principal component | 450000.00 |
| interest_rate | DECIMAL(5,2) | Final interest rate | 9.25 |
| tenure_months | INTEGER | Final tenure | 240 |
| emi_amount | DECIMAL(10,2) | Monthly EMI | 4087.50 |
| first_emi_date | DATE | First EMI due date | "2024-04-01" |
| maturity_date | DATE | Loan maturity date | "2044-03-01" |
| disbursal_method | VARCHAR(50) | Method of disbursal | "BANK_TRANSFER" |
| beneficiary_account | VARCHAR(20) | Beneficiary bank account | "HDFC-1234567890" |
| disbursed_at | TIMESTAMP | Disbursal timestamp | "2024-03-01 10:00:00" |
| disbursed_by | VARCHAR(100) | Disbursing officer | "Operations Manager" |

**EMI Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| emi_id | UUID | Primary key | "emi-uuid-001" |
| loan_account_number | VARCHAR(20) | Reference to loan | "HL202400001" |
| emi_number | INTEGER | EMI sequence number | 1 |
| due_date | DATE | EMI due date | "2024-04-01" |
| emi_amount | DECIMAL(10,2) | Total EMI amount | 4087.50 |
| principal_component | DECIMAL(10,2) | Principal portion | 1837.50 |
| interest_component | DECIMAL(10,2) | Interest portion | 2250.00 |
| outstanding_principal | DECIMAL(12,2) | Remaining principal | 448162.50 |
| payment_status | VARCHAR(30) | Payment status | "PAID" |
| paid_amount | DECIMAL(10,2) | Amount actually paid | 4087.50 |
| paid_date | TIMESTAMP | Payment timestamp | "2024-03-30 14:20:00" |
| payment_method | VARCHAR(50) | Payment mode | "AUTO_DEBIT" |
| late_fee | DECIMAL(8,2) | Late payment fee | 0.00 |
| bounce_charges | DECIMAL(8,2) | Bounce charges if any | 0.00 |
| receipt_number | VARCHAR(50) | Payment receipt number | "RCP202400001" |

**Loan Closure Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| closure_id | UUID | Primary key | "cls-uuid-001" |
| loan_account_number | VARCHAR(20) | Reference to loan | "HL202400001" |
| closure_type | VARCHAR(30) | Type of closure | "FORECLOSURE" |
| closure_date | TIMESTAMP | Closure timestamp | "2029-06-15 15:30:00" |
| outstanding_principal | DECIMAL(12,2) | Principal outstanding | 280000.00 |
| outstanding_interest | DECIMAL(12,2) | Interest outstanding | 15000.00 |
| penalty_charges | DECIMAL(10,2) | Penalty if any | 2000.00 |
| total_settlement_amount | DECIMAL(12,2) | Total payable | 297000.00 |
| amount_paid | DECIMAL(12,2) | Amount actually paid | 297000.00 |
| closure_reason | VARCHAR(100) | Reason for closure | "Customer prepayment" |
| noc_issued | BOOLEAN | No Objection Certificate | true |
| noc_number | VARCHAR(50) | NOC reference number | "NOC202900001" |
| closed_by | VARCHAR(100) | Closing authority | "Branch Manager" |
| refund_amount | DECIMAL(10,2) | Refund to customer | 0.00 |

### Strategic Denormalization for Operations

**Performance Problem:**
The normalized design required joining 6 tables for a single loan status query, resulting in 3-8 second response times for loan officers managing hundreds of applications.

**Loan Processing Dashboard Table (Denormalized)**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| loan_account_number | VARCHAR(20) | Primary loan reference | "HL202400001" |
| customer_name | VARCHAR(100) | Customer name | "Rajesh Kumar Singh" |
| customer_phone | VARCHAR(15) | Contact number | "+919876543210" |
| loan_amount | DECIMAL(12,2) | Original loan amount | 450000.00 |
| loan_type | VARCHAR(50) | Type of loan | "Home Loan" |
| current_status | VARCHAR(50) | Current loan status | "ACTIVE" |
| emi_amount | DECIMAL(10,2) | Monthly EMI | 4087.50 |
| next_due_date | DATE | Next EMI due date | "2024-05-01" |
| outstanding_principal | DECIMAL(12,2) | Current outstanding | 445000.00 |
| total_emis | INTEGER | Total number of EMIs | 240 |
| paid_emis | INTEGER | EMIs paid so far | 2 |
| remaining_emis | INTEGER | EMIs remaining | 238 |
| last_payment_date | DATE | Last payment date | "2024-04-30" |
| overdue_amount | DECIMAL(10,2) | Overdue if any | 0.00 |
| days_overdue | INTEGER | Days past due | 0 |
| risk_flag | VARCHAR(20) | Risk indicator | "GREEN" |
| relationship_manager | VARCHAR(100) | Assigned RM | "Priya Sharma" |
| last_updated | TIMESTAMP | Last update | "2024-04-30 18:00:00" |

### Query Performance Optimization

**Before (Normalized - Multiple Joins):**
Manager dashboard query requiring 6 table joins:
- Response time: 3-8 seconds for 10,000 loans
- Query complexity: JOIN across User, Loan_Request, Loan_Approval, Loan_Disbursal, EMI tables

**After (Denormalized - Single Table):**
Direct lookup from loan_processing_dashboard table:
- Response time: <200ms for 50,000 loans  
- Query complexity: Simple SELECT with WHERE clause
- Storage trade-off: +500MB for 10x faster queries

### Compliance Reporting Optimization

NBFC license required complex regulatory reports. Pre-computed metrics eliminated real-time calculations:

**Compliance Reporting Cache Table**
| Column | Data Type | Description | Sample Data |
|--------|-----------|-------------|-------------|
| report_date | DATE | Reporting date | "2024-03-31" |
| report_type | VARCHAR(50) | Report category | "RBI_MONTHLY" |
| total_loans_count | INTEGER | Active loans count | 1250 |
| total_loans_value | DECIMAL(15,2) | Portfolio value | 125000000.00 |
| npa_count | INTEGER | Non-performing assets | 15 |
| npa_value | DECIMAL(15,2) | NPA value | 2500000.00 |
| npa_percentage | DECIMAL(5,2) | NPA ratio | 2.00 |
| low_risk_loans | INTEGER | Low risk category | 1000 |
| medium_risk_loans | INTEGER | Medium risk category | 200 |
| high_risk_loans | INTEGER | High risk category | 50 |
| kyc_compliance_rate | DECIMAL(5,2) | KYC completion rate | 99.20 |
| documentation_completion_rate | DECIMAL(5,2) | Doc completion rate | 98.50 |
| sla_adherence_rate | DECIMAL(5,2) | SLA adherence | 95.80 |
| loan_type_breakdown | JSONB | Loan type distribution | {"home": 60, "personal": 30, "business": 10} |
| geography_breakdown | JSONB | State-wise distribution | {"Maharashtra": 40, "Karnataka": 25, "Delhi": 20} |
| vintage_analysis | JSONB | Age-wise analysis | {"0-1yr": 300, "1-3yr": 500, "3+yr": 450} |
| generated_at | TIMESTAMP | Report generation time | "2024-04-01 08:00:00" |

## Results Achieved

| Metric | Before | After | Improvement |
|--------|--------|--------|-------------|
| **Loan Officer Query Time** | 3-8 seconds | <200ms | 15-40x faster |
| **Process Steps Supported** | 5 steps | 40+ steps | 8x complexity |
| **Compliance Report Generation** | 2 hours | 5 minutes | 24x faster |
| **Concurrent Users** | 10 officers | 100+ officers | 10x scale |
| **Daily Loan Processing** | 50 applications | 500 applications | 10x throughput |

---

# Key Learnings: When to Normalize vs. Denormalize

## Decision Framework

| **Scenario** | **Approach** | **Reason** |
|--------------|--------------|------------|
| **High Read/Write Ratio (>10:1)** | Denormalize | Query performance over storage |
| **Complex Operational Workflows** | Denormalize | Reduce join complexity |
| **Regulatory Reporting** | Denormalize | Pre-computed aggregates |
| **Transactional Integrity Critical** | Normalize | ACID compliance |
| **Rapid Schema Evolution** | Hybrid | Flexibility with performance |

## Strategic Denormalization Guidelines

âœ… **When to Denormalize:**
- Query patterns are predictable and repetitive
- Read performance directly impacts user experience
- Operational workflows require quick decision-making
- Compliance reporting has strict time requirements

âŒ **When to Stay Normalized:**
- Data consistency is more critical than performance
- Schema changes frequently
- Storage costs are a major concern
- Write patterns are unpredictable

## Conclusion

Database design success comes from understanding your product's specific needs and user behavior patterns. Each of these three systems succeeded because the database architecture aligned perfectly with the product requirements:

- **Fantasy Football:** Optimized for burst reads and predictable query patterns
- **Airline Reservations:** Designed for schema evolution and version compatibility  
- **Loan Management:** Structured for operational efficiency and regulatory compliance

The key insight is that there's no universal "best" database designâ€”only designs that work well for specific product contexts. Understanding your users' workflows, your business constraints, and your operational requirements is far more valuable than following theoretical database design rules.
